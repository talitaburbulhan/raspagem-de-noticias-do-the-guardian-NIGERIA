{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pensamento_Computacional_Trabalho_Final (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talitaburbulhan/raspagem-de-noticias-do-the-guardian-NIGERIA/blob/main/Pensamento_Computacional_Trabalho_Final_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyAdn4JILSzL"
      },
      "source": [
        "Objetivo do programa: **extrair o t√≠tulo e o link das mat√©rias** do site do The Guardian que faz a cobertura da Nig√©ria: \n",
        "\n",
        "üåê https://guardian.ng/category/news/nigeria/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR70iuiEOVWn"
      },
      "source": [
        "1Ô∏è‚É£ MANIPUALA√á√ÉO DE STRING\n",
        "\n",
        "No HTML original tenho acesso √†s 18 mat√©rias da primeira p√°gina. Com a t√©cnica da manipula√ß√£o de strings foi poss√≠vel extra√≠-las:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ye-3U-6iPBkO"
      },
      "source": [
        "import requests\n",
        "url = \"https://guardian.ng/category/news/nigeria/\"\n",
        "resposta = requests.get(url)\n",
        "html = resposta.text\n",
        "\n",
        "partes = html.split('<span class=\"title\" data-field=\"title\"><a href=\"')\n",
        "for parte in partes:\n",
        "  subpartes = parte.split(\"</div>\")\n",
        "  conteudo = subpartes[0]\n",
        "  if \"</a></span>\" not in conteudo:\n",
        "    continue\n",
        "  linha = conteudo.strip()\n",
        "  registro = linha.split(\"</a></span>\")\n",
        "  link_e_titulo_juntos = registro[0]\n",
        "  link, titulo = link_e_titulo_juntos.split('\" data-field=\"title-link\">')\n",
        "  print(link, titulo) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzWF1aFwTTUz"
      },
      "source": [
        "üëçüèº O c√≥digo funcionou! \n",
        "\n",
        "üëéüèº S√≥ conseguiu pegar os links e t√≠tulos da primeira p√°gina. Para conseguir mais resultados tive que usar outra t√©cnica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE3dCQZQRwOc"
      },
      "source": [
        "2Ô∏è‚É£ ARQUIVO JSON:\n",
        "\n",
        "Ao inspecionar o site, pela aba Network, e clicar no bot√£o \"LOAD MORE\" uma das requisi√ß√µes √© um arquivo JSON. \n",
        "\n",
        "Para conseguir extrair links e t√≠tulos al√©m dos que estavam na primeira p√°gina, foi fundamental analisar a estrutura da URL:\n",
        "https://guardian.ng/wp-json/wp/v2/posts?offset=12&per_page=12&orderby=date&order=d[‚Ä¶]776%2C1553760%2C1553292%2C1553300%2C1553286%2C1553315%2C1553517  \n",
        "\n",
        "Ela possui um **OFFSET=12** e um **PER_PAGE=12**. √Ålvaro me orientou a mudar os n√∫mero desses par√¢metros. Coloquei OFFSET=0 E PER_PAGE=100, dessa maneira consegui extrair as 100 √∫ltimas mat√©rias do site.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IALGDaYqKqYN"
      },
      "source": [
        "import requests\n",
        "url = \"https://guardian.ng/wp-json/wp/v2/posts?offset=0&per_page=100&orderby=date&order=desc&categories=46751%2C4%2C3%2C46753&exclude=1555218%2C1554939%2C1555082%2C1555031%2C1555065%2C1555075%2C1555085%2C1555099%2C1555064%2C1554965%2C1554948%2C1554938%2C1554846\"\n",
        "resposta = requests.get(url)\n",
        "dados = (resposta.json()) \n",
        "\n",
        "for noticia in dados:                                                   \n",
        "  materia, link = (noticia[\"title\"][\"rendered\"], noticia[\"link\"])      ## Esse JSON √© uma lista e cada item da lista era um dicion√°rio. \n",
        "  print(materia, link)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y3XKhbiW_HS"
      },
      "source": [
        "üëçüèº O c√≥digo funcionouou e eu tive mais registros.\n",
        "\n",
        "üëéüèº S√≥ conseguiu pegar as 100 √∫ltimas mat√©rias. E se eu quisesse ter acesso a conte√∫dos mais antigos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQI7m2eq9Sh1"
      },
      "source": [
        "Criei uma fun√ß√£o chamada `extrai_dados` que tem os seguintes par√¢metros: \"offset\" e \"per_page\". Dessa maneira, posso chamar a fun√ß√£o diversas vezes, sendo que a cada vez, posso conseguir at√© 100 novos links. No c√≥digo abaixo, a fun√ß√£o foi chamada 3 vezes. O resultado foi um arquivo .CSV com os 300 √∫ltimos links e t√≠tulos de mat√©rias postadas no site. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_cNCdKgK7BT"
      },
      "source": [
        "üëáüèº C√≥digo final, com o trecho que exporta para CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw3jML4jJp64"
      },
      "source": [
        "def extrai_dados(offset, per_page):\n",
        "  import requests\n",
        "  url = f\"https://guardian.ng/wp-json/wp/v2/posts?offset={offset}&per_page={per_page}&orderby=date&order=desc&categories=46751%2C4%2C3%2C46753&exclude=1555218%2C1554939%2C1555082%2C1555031%2C1555065%2C1555075%2C1555085%2C1555099%2C1555064%2C1554965%2C1554948%2C1554938%2C1554846\"\n",
        "  resposta = requests.get(url)\n",
        "  dados = (resposta.json()) \n",
        "  lista_materias = []\n",
        "  for noticia in dados:                                                   \n",
        "    materia, link = (noticia[\"title\"][\"rendered\"], noticia[\"link\"])\n",
        "    dicio = {\"materia\": materia, \"link\":link}  \n",
        "    lista_materias.append(dicio)\n",
        "  return lista_materias\n",
        "\n",
        "import csv\n",
        "arquivo = open(\"materias-nigeria-7.csv\", mode=\"w\")\n",
        "escritor = csv.DictWriter(arquivo, fieldnames = [\"materia\", \"link\"] )\n",
        "escritor.writeheader()\n",
        "primeiro_bloco = extrai_dados(0,100)\n",
        "segunto_bloco = extrai_dados(100,100)\n",
        "terceiro_bloco = extrai_dados(200,100)\n",
        "blocos = primeiro_bloco + segundo_bloco + terceiro_bloco \n",
        "for resultado in blocos:\n",
        "  escritor.writerow(resultado) \n",
        "arquivo.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}